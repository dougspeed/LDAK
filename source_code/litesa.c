/*
Copyright 2024 Doug Speed.

    LDAK is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.

    LDAK is distributed in the hope that they will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.

    You should have received a copy of the GNU General Public License along with LDAK.  If not, see <http://www.gnu.org/licenses/>.

*/

///////////////////////////

//Construct prediction models from summary statistics - assumes phenotype has variance one (also standardize predictors)
//I took out forced predictors and jackknife (but can find in litesa2.c in old folder)

///////////////////////////

//set and save parameters (will allocate trytypes, tryhers, trylams, tryscales, tryps, tryf2s)
#include "setparamsb.c"

//neff is the average sample size for the main summaries
sum=0;for(j=0;j<data_length;j++){sum+=nss[j];}
neff=sum/data_length;

//set bitmax to size of longest chromosome (hard to predict size of longest bit)
bitmax=0;
bitstart=0;
while(bitstart<data_length)
{
for(bitend=bitstart+1;bitend<data_length;bitend++)
{
if(chr[bitend]!=chr[bitstart]){break;}
}
if(bitend-bitstart>bitmax){bitmax=bitend-bitstart;}
bitstart=bitend;
}

if(skipcv==0)	//using pseudo cross-validation - get pseudos and also neff2, average size for training summaries
{
//only need nss2, rhos2 and rhos3 (not nss3 or chis2 / chis3)
nss2=malloc(sizeof(double)*data_length);
rhos2=malloc(sizeof(double)*data_length);
rhos3=malloc(sizeof(double)*data_length);

if(cvprop!=-9999)	//make them from cors.noise
{
//allocate and read datarands
datarands=malloc(sizeof(double)*data_length);
sprintf(filename,"%s.cors.noise", corname);
read_values(filename,datarands,data_length,keeppreds_use,1,0,0);

//set nss2
for(j=0;j<data_length;j++){nss2[j]=(1-cvprop)*nss[j];}

//rhos2 is rhos plus datarands*root(cvprop/(1-cvprop)/nss)
value=pow(cvprop/(1-cvprop),.5);
for(j=0;j<data_length;j++){rhos2[j]=rhos[j]+datarands[j]*value*pow(nss[j],-.5);}

//rhos3 is complement
for(j=0;j<data_length;j++){rhos3[j]=(rhos[j]-(1-cvprop)*rhos2[j])/cvprop;}

free(datarands);
}
else	//read from pseudo files
{
//will also read nss3, chis2 and chis3 (then delete)
nss3=malloc(sizeof(double)*data_length);
chis2=malloc(sizeof(double)*data_length);
chis3=malloc(sizeof(double)*data_length);

sprintf(filename2,"%s.train.summaries", pseudostem);
printf("Reading training summary statistics from %s\n", filename2);
read_sumsfile(filename2, nss2, chis2, rhos2, data_length, preds, al1, al2, bimfile, amb, -9999, 1.0, 0, -9999);
printf("First few stats and ns are: %s %.3f %.1f", preds[0], chis2[0], nss2[0]);
for(j=1;j<data_length;j++){if(j<3){printf(" | %s %.3f %.1f", preds[j], chis2[j], nss2[j]);}}
printf("\n\n");

sprintf(filename3,"%s.test.summaries", pseudostem);
printf("Reading test summary statistics from %s\n", filename3);
read_sumsfile(filename3, nss3, chis3, rhos3, data_length, preds, al1, al2, bimfile, amb, -9999, 1.0, 0, -9999);
printf("First few stats and ns are: %s %.3f %.1f", preds[0], chis3[0], nss3[0]);
for(j=1;j<data_length;j++){if(j<3){printf(" | %s %.3f %.1f", preds[j], chis3[j], nss3[j]);}}
printf("\n\n");

free(nss3);free(chis2);free(chis3);
}

sum=0;for(j=0;j<data_length;j++){sum+=nss2[j];}
neff2=sum/data_length;
}

if(skipcv==0)	//set highlds, which indicates which predictors to exclude when testing models
{
highlds=malloc(sizeof(int)*data_length);
for(j=0;j<data_length;j++){highlds[j]=0;}

if(checkld==1)	//read predictors to exclude
{
if(strcmp(ldfile,"blank")==0)	//use file generated by calc-cors
{
sprintf(filename,"%s.cors.highld", corname);
count=countrows(filename);

head=check_head(filename,"None","None",0);

if(head==1){printf("There are no high-LD predictors (%s is empty)\n\n", filename);}
else
{
printf("Reading list of %d high-LD predictors from %s\n", count, filename);
wantpreds=malloc(sizeof(char*)*count);
indexer=malloc(sizeof(int)*data_length);
read_strings(filename, wantpreds, count, NULL, 1, 0);

count2=find_strings(preds, data_length, wantpreds, count, indexer, NULL, NULL, NULL, NULL, NULL, 3);
if(count2==0){printf("Warning, none of the predictors are in the data\n\n");}
if(count2>0&&count2<count){printf("Warning, only %d of these are in the data\n\n", count2);}
if(count2==count){printf("All of these are in the data\n\n");}

for(j=0;j<count2;j++){highlds[indexer[j]]=1;}

for(j=0;j<count;j++){free(wantpreds[j]);}free(wantpreds);free(indexer);
}
}
else	//exclude predictors in ldfile
{
count=countrows(ldfile);
printf("Reading list of %d high-LD predictors from %s\n", count, ldfile);
wantpreds=malloc(sizeof(char*)*count);
indexer=malloc(sizeof(int)*data_length);
read_strings(ldfile, wantpreds, count, NULL, 1, 0);

count2=find_strings(preds, data_length, wantpreds, count, indexer, NULL, NULL, NULL, NULL, NULL, 3);
if(count2==0){printf("Warning, none of the predictors are in the data\n\n");}
if(count2>0&&count2<count){printf("Warning, only %d of these are in the data\n\n", count2);}
if(count2==count){printf("All of these are in the data\n\n");}

for(j=0;j<count2;j++){highlds[indexer[j]]=1;}

for(j=0;j<count;j++){free(wantpreds[j]);}free(wantpreds);free(indexer);
}
}
}

////////

//deal with correlations

maxnums=malloc(sizeof(int)*num_preds);
scumsums=malloc(sizeof(size_t)*num_preds);

sprintf(filename,"%s.cors.bin", corname);
if((input=fopen(filename,"rb"))==NULL)
{printf("Error opening %s\n\n",filename);exit(1);}
if(fread(maxnums, sizeof(int), num_preds, input)!=num_preds)
{printf("Error reading counts from %s\n\n", filename);exit(1);}
fclose(input);

scumsums[0]=0;for(j=1;j<num_preds;j++){scumsums[j]=scumsums[j-1]+maxnums[j-1];}

scount=0;for(j=0;j<data_length;j++){scount+=maxnums[keeppreds_use[j]];}
value=(double)scount/1024/1024/1024*8;
if(value>1){printf("Warning, to read the correlations requires %.1f Gb\n\n", value);}

bigs=malloc(sizeof(int*)*data_length);
rjks=malloc(sizeof(float*)*data_length);
for(j=0;j<data_length;j++)
{
bigs[j]=malloc(sizeof(int)*maxnums[keeppreds_use[j]]);
rjks[j]=malloc(sizeof(float)*maxnums[keeppreds_use[j]]);
}

usedpreds=malloc(sizeof(int)*num_preds);
actnums=malloc(sizeof(int)*data_length);
rjksums=malloc(sizeof(double)*data_length);

//allocate remaining variables

anal_warn(data_length, 3*num_try);

datasqs=malloc(sizeof(double)*data_length);
YTdata=malloc(sizeof(double)*data_length);

exps=malloc(sizeof(double)*data_length);

lambdas=malloc(sizeof(double)*num_try);
lambdas2=malloc(sizeof(double)*num_try);
lambdas3=malloc(sizeof(double)*num_try);
lambdas4=malloc(sizeof(double)*num_try);

effs=malloc(sizeof(double)*data_length*num_try);
effs2=malloc(sizeof(double)*bitmax*num_try);
probs=malloc(sizeof(double)*data_length*num_try);
probs2=malloc(sizeof(double)*bitmax*num_try);

convs=malloc(sizeof(int)*data_length*num_try);

if(skipcv==0)
{
predvars=malloc(sizeof(double)*num_try);
predcors=malloc(sizeof(double)*num_try);
}

////////

//reopen cors
sprintf(filename,"%s.cors.bin", corname);
if((input=fopen(filename,"rb"))==NULL)
{printf("Error re-opening %s\n\n",filename);exit(1);}

//read means, allowing for filtering
fseeko(input, (off_t)sizeof(int)*num_preds, SEEK_SET);
current=0;
for(j=0;j<data_length;j++)
{
if(keeppreds_use[j]!=current)
{fseeko(input, (off_t)sizeof(int)*num_preds+sizeof(double)*keeppreds_use[j], SEEK_SET);}
if(fread(centres+j, sizeof(double), 1, input)!=1)
{printf("Error reading mean for Predictor %d from %s\n\n", j+1, filename);exit(1);}
current=keeppreds_use[j]+1;
}

//now scalings, allowing for filtering
fseeko(input, (off_t)sizeof(int)*num_preds+sizeof(double)*num_preds, SEEK_SET);
current=0;
for(j=0;j<data_length;j++)
{
if(keeppreds_use[j]!=current)
{fseeko(input, (off_t)sizeof(int)*num_preds+sizeof(double)*num_preds+sizeof(double)*keeppreds_use[j], SEEK_SET);}
if(fread(mults+j, sizeof(double), 1, input)!=1)
{printf("Error reading scaling for Predictor %d from %s\n\n", j+1, filename);exit(1);}
current=keeppreds_use[j]+1;
}

//and variances, allowing for filtering
fseeko(input, (off_t)sizeof(int)*num_preds+sizeof(double)*num_preds*2, SEEK_SET);
current=0;
for(j=0;j<data_length;j++)
{
if(keeppreds_use[j]!=current)
{fseeko(input, (off_t)sizeof(int)*num_preds+sizeof(double)*num_preds*2+sizeof(double)*keeppreds_use[j], SEEK_SET);}
if(fread(sqdevs+j, sizeof(double), 1, input)!=1)
{printf("Error reading variance for Predictor %d from %s\n\n", j+1, filename);exit(1);}
current=keeppreds_use[j]+1;
}

//finally read correlations - first with crude filtering
fseeko(input, (off_t)sizeof(int)*num_preds+sizeof(double)*num_preds*3, SEEK_SET);
current=0;
for(j=0;j<data_length;j++)
{
if(maxnums[keeppreds_use[j]]>0)
{
if(keeppreds_use[j]!=current)
{fseeko(input, (off_t)sizeof(int)*num_preds+sizeof(double)*num_preds*3+(sizeof(int)+sizeof(float))*scumsums[keeppreds_use[j]], SEEK_SET);}
if(fread(bigs[j], sizeof(int), maxnums[keeppreds_use[j]], input)!=maxnums[keeppreds_use[j]])
{printf("Error reading indexes for Predictor %d from %s\n\n", j+1, filename);exit(1);}
if(fread(rjks[j], sizeof(float), maxnums[keeppreds_use[j]], input)!=maxnums[keeppreds_use[j]])
{printf("Error reading correlations for Predictor %d from %s\n\n", j+1, filename);exit(1);}
current=keeppreds_use[j]+1;
}
}
fclose(input);

//set actnums and rjksums, and multiply rjks by shrink (this also finishes any filtering)
for(j=0;j<num_preds;j++){usedpreds[j]=-1;}
for(j=0;j<data_length;j++){usedpreds[keeppreds_use[j]]=j;}

for(j=0;j<data_length;j++)
{
count=0;
sum=1;
for(j2=0;j2<maxnums[keeppreds_use[j]];j2++)
{
j3=bigs[j][j2];
if(usedpreds[j3]!=-1)	//predictor remains (and has been mapped to usedpreds[j3])
{
sum+=pow(rjks[j][j2],2);
bigs[j][count]=usedpreds[j3];
rjks[j][count]=shrink*rjks[j][j2];
count++;
}
}
actnums[j]=count;
rjksums[j]=sum;
}

////////

//fill exps, which contains expected per-predicted heritabilies (sum to one)

if(strcmp(indhers,"blank")!=0)	//already have
{
for(j=0;j<data_length;j++){exps[j]=weights[j];}
}
else
{
count=0;
for(j=0;j<data_length;j++)
{
if(mults[j]!=-9999)
{
if(hwestand==1){exps[j]=weights[j]*pow(centres[j]*(1-centres[j]/2),1+power);}
else{exps[j]=weights[j]*pow(sqdevs[j],1+power);}
count++;
}
else{exps[j]=0;}
}
if(count==0){printf("Error, all predictors are trivial\n\n");exit(1);}

//make sure exps sum to one
sum=0;for(j=0;j<data_length;j++){sum+=exps[j];}
for(j=0;j<data_length;j++){exps[j]=exps[j]/sum;}
}

//set lambdas (values corresponding to exps=her=varphen=1 - will later scale)
for(p=0;p<num_try;p++)
{
//start at zero, then change when required
lambdas[p]=0;lambdas2[p]=0;lambdas3[p]=0;lambdas4[p]=0;

if(trytypes[p]==1)	//lasso-sparse - lambda is set to match the lassosum paper
{lambdas[p]=trylams[p]*pow(data_length,-.5);}

if(trytypes[p]==2)	//lasso-shrink - exp(betaj^2) = 2/lam^2
{lambdas[p]=pow(2,.5);}

if(trytypes[p]==3)	//ridge - exp(betaj^2) = lam
{lambdas[p]=1.0;}

if(trytypes[p]==4)	//bolt - exp(betaj^2) = plam + p2lam2, with p2lam2/plam = f2/(1-f2) - p and p2 within (0,1)
{
lambdas[p]=(1-tryf2s[p])/tryps[p];
lambdas2[p]=tryf2s[p]/tryp2s[p];
}

if(trytypes[p]==5)	//bayesr-sparse - exp(betaj^2) = p2lam2 + p3lam3 + p4lam4
{
value=tryp2s[p]/100+tryp3s[p]/10+tryp4s[p];
lambdas[p]=0.0;
lambdas2[p]=0.01/value;
lambdas3[p]=0.1/value;
lambdas4[p]=1.0/value;
}

if(trytypes[p]==6)	//bayesr-shrink - exp(betaj^2) =  plam + p2lam2 + p3lam3 + p4lam4
{
value=tryps[p]/1000+tryp2s[p]/100+tryp3s[p]/10+tryp4s[p];
lambdas[p]=0.001/value;
lambdas2[p]=0.01/value;
lambdas3[p]=0.1/value;
lambdas4[p]=1.0/value;
}

if(trytypes[p]==7)	//elastic - exp(betaj^2) = p/lam^2 + p2/lam2^2 + p3lam3
{
if(tryp3s[p]==0)	//lasso
{lambdas[p]=1.0;lambdas2[p]=1.0;}
if(tryp3s[p]==1)	//ridge
{lambdas3[p]=1.0;}
if(tryp3s[p]>0||tryp3s[p]<1)	//elastic
{
lambdas[p]=pow(4*tryps[p]/(1-tryf2s[p]),.5);
lambdas2[p]=pow(4*tryp2s[p]/(1-tryf2s[p]),.5);
lambdas3[p]=tryf2s[p]/tryp3s[p];
}
}
}	//end of p loop

//blank progress file
sprintf(filename,"%s.progress",outfile);
if((output=fopen(filename,"w"))==NULL)
{printf("Error writing to %s; check you have permission to write and that there does not exist a folder with this name\n\n",filename);exit(1);}
fclose(output);

///////////////////////

if(skipcv==0)	//solve using training summaries - var(Y)=1, so YTY=neff2 - then test using test summaries
{
if(num_try==1)	//trivial case - just need to set best to zero
{
printf("Can skip training phase because there is only set of parameters\n\n");

sprintf(filename,"%s.progress",outfile);
if((output=fopen(filename,"a"))==NULL)
{printf("Error re-opening %s\n\n",filename);exit(1);}
fprintf(output,"Can skip training phase because there is only set of parameters\n");
fclose(output);

best=0;
}
else
{
//screen and file print
if(num_try==1){printf("Estimating effect sizes for one model using pseudo training summary statistics\n\n");}
else{printf("Estimating effect sizes for %d models using pseudo training summary statistics (if using multiple cores, models will finish in a random order)\n\n", num_try);}

if((output=fopen(filename,"a"))==NULL)
{printf("Error re-opening %s\n\n",filename);exit(1);}
fprintf(output,"Constructing %d models using pseudo training summary statistics\n", num_try);
fprintf(output, "Model\tType\tHeritability\tlambda\tscale\tp\tf2\tp1\tp2\tp3\tp4\t\tNum_Predictors_Failed\n");
fclose(output);

//get XTX and XTY for each predictor
for(j=0;j<data_length;j++){datasqs[j]=neff2;YTdata[j]=rhos2[j]*neff2;}

//set starting effects based on type of model
#pragma omp parallel for private(p,j,value,value2) schedule(dynamic, 1)
for(p=0;p<num_try;p++)
{
for(j=0;j<data_length;j++)
{
if(exps[j]>0)
{
//value and value2 are how much to scale gaussian and laplace parameters
value=exps[j]*tryhers[p];
value2=pow(exps[j]*tryhers[p],-.5);

if(trytypes[p]==1)	//lasso-sparse - set to zero
{effs[(size_t)p*data_length+j]=0;}
if(trytypes[p]==2)	//lasso - posterior mean, weighted by tagging
{effs[(size_t)p*data_length+j]=get_postmean(YTdata[j], lambdas[p]*value2, -9999, -9999, -9999, datasqs[j], 1.0, -9999, -9999, -9999, -9999, NULL, 2, NULL)/rjksums[j];}
if(trytypes[p]==3)	//ridge - posterior mean, weighted by tagging
{effs[(size_t)p*data_length+j]=get_postmean(YTdata[j], lambdas[p]*value, -9999, -9999, -9999, datasqs[j], 1.0, -9999, -9999, -9999, -9999, NULL, 3, NULL)/rjksums[j];}
if(trytypes[p]==4)	//bolt - posterior mean, weighted by tagging
{effs[(size_t)p*data_length+j]=get_postmean(YTdata[j], lambdas[p]*value, lambdas2[p]*value, -9999, -9999, datasqs[j], 1.0, tryps[p], tryp2s[p], -9999, -9999, NULL, 4, NULL)/rjksums[j];}
if(trytypes[p]==5||trytypes[p]==6)	//bayesr or bayesr-shrink - posterior mean, weighted by tagging
{effs[(size_t)p*data_length+j]=get_postmean(YTdata[j], lambdas[p]*value, lambdas2[p]*value, lambdas3[p]*value, lambdas4[p]*value, datasqs[j], 1.0, tryps[p], tryp2s[p], tryp3s[p], tryp4s[p], NULL, trytypes[p], NULL)/rjksums[j];}
if(trytypes[p]==7)	//elastic - posterior mean, weighted by tagging
{effs[(size_t)p*data_length+j]=get_postmean(YTdata[j], lambdas[p]*value2, lambdas2[p]*value2, lambdas3[p]*value, -9999, datasqs[j], 1.0, tryps[p], tryp2s[p], tryp3s[p], -9999, NULL, 7, NULL)/rjksums[j];}
}
effs[(size_t)p*data_length+j]=0;}
}

//now ready to train models
#pragma omp parallel for private(p,j,j2,count,bitstart,bitstart2,bitend,bitlength,sum,value,value2,sumsq,sumsq2,window_kb2) schedule(dynamic, 1)
for(p=0;p<num_try;p++)
{
//set convs to zero
for(j=0;j<data_length;j++){convs[(size_t)p*data_length+j]=0;}

window_kb2=window_kb/segments;
bitstart=0;
while(bitstart<data_length)
{
for(bitend=bitstart+1;bitend<data_length;bitend++)
{
if(cmbp[bitend]-cmbp[bitstart]>1000*window_kb2||chr[bitend]!=chr[bitstart]){break;}
}
bitlength=bitend-bitstart;

//calculate ess for bit
sumsq=0;
for(j=bitstart;j<bitend;j++)
{
sumsq+=2*YTdata[j]*effs[(size_t)p*data_length+j]-datasqs[j]*pow(effs[(size_t)p*data_length+j],2);
for(j2=0;j2<actnums[j];j2++)
{
if(bigs[j][j2]>=bitstart&&bigs[j][j2]<bitend)
{sumsq-=rjks[j][j2]*neff2*effs[(size_t)p*data_length+j]*effs[(size_t)p*data_length+bigs[j][j2]];}
}
}

//save effect sizes for bit, in case fail to converge
for(j=0;j<bitlength;j++){effs2[j+p*bitmax]=effs[(size_t)p*data_length+bitstart+j];}

count=0;
while(1)
{
count++;

for(j=bitstart;j<bitend;j++)
{
if(exps[j]>0)
{
//get XjT residuals
sum=YTdata[j];
for(j2=0;j2<actnums[j];j2++){sum-=tryscales[p]*rjks[j][j2]*neff2*effs[(size_t)p*data_length+bigs[j][j2]];}

//value and value2 are how much to scale gaussian and laplace parameters
value=exps[j]*tryhers[p];
value2=pow(exps[j]*tryhers[p],-.5);

//update effect size
if(trytypes[p]==1)	//lasso-sparse
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value2*neff2, -9999, -9999, -9999, datasqs[j], 1.0, -9999, -9999, -9999, -9999, NULL, 1, NULL);}
if(trytypes[p]==2)	//lasso
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value2, -9999, -9999, -9999, datasqs[j], 1.0, -9999, -9999, -9999, -9999, NULL, 2, NULL);}
if(trytypes[p]==3)	//ridge
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value, -9999, -9999, -9999, datasqs[j], 1.0, -9999, -9999, -9999, -9999, NULL, 3, NULL);}
if(trytypes[p]==4)	//bolt
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value, lambdas2[p]*value, -9999, -9999, datasqs[j], 1.0, tryps[p], tryp2s[p], -9999, -9999, NULL, 4, NULL);}
if(trytypes[p]==5||trytypes[p]==6)	//bayesr or bayesr-shrink
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value, lambdas2[p]*value, lambdas3[p]*value, lambdas4[p]*value, datasqs[j], 1.0, tryps[p], tryp2s[p], tryp3s[p], tryp4s[p], NULL, trytypes[p], NULL);}
if(trytypes[p]==7)	//elastic
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value2, lambdas2[p]*value2, lambdas3[p]*value, -9999, datasqs[j], 1.0, tryps[p], tryp2s[p], tryp3s[p], -9999, NULL, 7, NULL);}
}
}	//end of j loop

//save old then calculate new ess for bit
sumsq2=sumsq;
sumsq=0;
for(j=bitstart;j<bitend;j++)
{
sumsq+=2*YTdata[j]*effs[(size_t)p*data_length+j]-datasqs[j]*pow(effs[(size_t)p*data_length+j],2);
for(j2=0;j2<actnums[j];j2++)
{
if(bigs[j][j2]>=bitstart&&bigs[j][j2]<bitend)
{sumsq-=rjks[j][j2]*neff2*effs[(size_t)p*data_length+j]*effs[(size_t)p*data_length+bigs[j][j2]];}
}
}

if(fabs(sumsq-sumsq2)/neff2<tol)	//converged
{
for(j=bitstart;j<bitend;j++){convs[(size_t)p*data_length+j]=1;}

if(window_kb2==window_kb)	//did a full window, so move start forwards window_kb/segments
{
for(bitstart2=bitstart+1;bitstart2<data_length;bitstart2++)
{
if(cmbp[bitstart2]-cmbp[bitstart]>1000*window_kb/segments||chr[bitstart2]!=chr[bitstart]){break;}
}
if(bitstart2==bitend)	//must have been at end of chromosome
{window_kb2=window_kb/segments;}
bitstart=bitstart2;
}
else	//did a small window, so start stays same, but increase window wise
{window_kb2*=2;}

break;
}

if(sumsq>=neff2||count==maxiter)	//failed (almost certainly due to end of bit) - undo iterations, skip rest of bit, and reduce window size 
{
//note that if here, bitstart will not have been updated
for(j=0;j<bitlength;j++){effs[(size_t)p*data_length+bitstart+j]=effs2[j+p*bitmax];}
bitstart=bitend;
window_kb2=window_kb/segments;
break;
}
}	//end of inside while loop
}	//end of outside while loop

//count how many failed to converged
count=0;for(j=0;j<data_length;j++){count+=(exps[j]>0&&convs[(size_t)p*data_length+j]==0);}

//print update
#pragma omp critical
{
printf("Constructed Model %d: ", p+1);
if(trytypes[p]==1){printf("lasso-sparse, lambda %.4f, scale %.2f", trylams[p], tryscales[p]);}
if(trytypes[p]==2){printf("lasso, heritability %.4f", tryhers[p]);}
if(trytypes[p]==3){printf("ridge, heritability %.4f", tryhers[p]);}
if(trytypes[p]==4){printf("bolt, heritability %.4f, p %.4f, f2 %.4f", tryhers[p], tryps[p], tryf2s[p]);}
if(trytypes[p]==5){printf("bayesr, heritability %.4f, p1 %.4f, p2 %.4f, p3 %.4f, p4 %.4f", tryhers[p], tryps[p], tryp2s[p], tryp3s[p], tryp4s[p]);}
if(trytypes[p]==6){printf("bayesr-shrink, heritability %.4f, p1 %.4f, p2 %.4f, p3 %.4f, p4 %.4f", tryhers[p], tryps[p], tryp2s[p], tryp3s[p], tryp4s[p]);}
if(trytypes[p]==7){printf("elastic, heritability %.4f, p %.4f, f2 %.4f", tryhers[p], 1-tryp3s[p], tryf2s[p]);}
if(count==0){printf(" - effect sizes converged for all predictors\n");}
else{printf(" - effect sizes failed to converge for %d predictors\n", count);}

if((output=fopen(filename,"a"))==NULL)
{printf("Error re-opening %s\n\n",filename);exit(1);}
fprintf(output, "%d\t", p+1);
if(trytypes[p]==1){fprintf(output, "lasso-sparse\tNA\t%.4f\t%.4f\tNA\tNA\tNA\tNA\tNA\tNA\t%d\n", trylams[p], tryscales[p], count);}
if(trytypes[p]==2){fprintf(output, "lasso\t%.4f\tNA\tNA\tNA\tNA\tNA\tNA\tNA\tNA\t%d\n", tryhers[p], count);}
if(trytypes[p]==3){fprintf(output, "ridge\t%.4f\tNA\tNA\tNA\tNA\tNA\tNA\tNA\tNA\t%d\n", tryhers[p], count);}
if(trytypes[p]==4){fprintf(output, "bolt\t%.4f\tNA\tNA\t%.4f\t%.4f\tNA\tNA\tNA\tNA\t%d\n", tryhers[p], tryps[p], tryf2s[p], count);}
if(trytypes[p]==5){fprintf(output, "bayesr\t%.4f\tNA\tNA\tNA\tNA\t%.4f\t%.4f\t%.4f\t%.4f\t%d\n", tryhers[p], tryps[p], tryp2s[p], tryp3s[p], tryp4s[p], count);}
if(trytypes[p]==6){fprintf(output, "bayesr-shrink\t%.4f\tNA\tNA\tNA\tNA\t%.4f\t%.4f\t%.4f\t%.4f\t%d\n", tryhers[p], tryps[p], tryp2s[p], tryp3s[p], tryp4s[p], count);}
if(trytypes[p]==7){fprintf(output, "elastic\t%.4f\tNA\tNA\t%.4f\t%.4f\tNA\tNA\tNA\tNA\t%d\n", tryhers[p], 1-tryp3s[p], tryf2s[p], count);}
fclose(output);
}
}	//end of p loop
printf("\n");

//test the models, and record the best (note that if exps[j]=0, the predictor will have effect zero)
printf("Testing the models using pseudo test summary statistics\n");

#pragma omp parallel for private(p,j,j2,value) schedule(dynamic, 1)
for(p=0;p<num_try;p++)
{
//get var(score) = sum betaj betak cor(Xj,Xk)
value=0;
for(j=0;j<data_length;j++)
{
if(highlds[j]==0)
{
value+=pow(effs[(size_t)p*data_length+j],2);
for(j2=0;j2<actnums[j];j2++)
{
if(highlds[bigs[j][j2]]==0){value+=effs[(size_t)p*data_length+j]*effs[(size_t)p*data_length+bigs[j][j2]]*rjks[j][j2];}
}
}}
if(value>0){predvars[p]=value;}
else{predvars[p]=-9999;}

//get cov(score,Y) = weighted sum of cov(Xj,Y) = weighted sum of rhos[j]
value=0;
for(j=0;j<data_length;j++)
{
if(highlds[j]==0){value+=effs[(size_t)p*data_length+j]*rhos3[j];}
}

//compute correlation (if possible)
if(predvars[p]!=-9999){predcors[p]=value*pow(predvars[p],-.5);}
else{predcors[p]=-9999;}
}

//find best
best=-1;
for(p=0;p<num_try;p++)
{
if(predcors[p]!=-9999)
{
if(best==-1){best=p;value=predcors[p];}
if(predcors[p]>value){best=p;value=predcors[p];}
}
}

if(best==-1)	//not possible to compute a correlation for any models
{printf("Error, it was not possible to compute a correlation for any of the models (suggesting they all have zero effect sizes)\n\n");exit(1);}

//save correlations
sprintf(filename2,"%s.cors",outfile);
if((output2=fopen(filename2,"w"))==NULL)
{printf("Error writing to %s; check you have permission to write and that there does not exist a folder with this name\n\n",filename2);exit(1);}
fprintf(output2,"Model\tCorrelation\n");

for(p=0;p<num_try;p++)
{
if(predcors[p]!=-9999){fprintf(output2,"%d\t%.6f\n", p+1, predcors[p]);}
else{fprintf(output2,"%d\tNA\tNA\n", p+1);}
}
fclose(output2);

//save the best model
sprintf(filename3,"%s.best",outfile);
if((output3=fopen(filename3,"w"))==NULL)
{printf("Error writing to %s; check you have permission to write and that there does not exist a folder with this name\n\n",filename3);exit(1);}
fprintf(output3, "Model\tType\tHeritability\tlambda\tscale\tp\tf2\tp1\tp2\tp3\tp4\n");

if(trytypes[best]==1){fprintf(output3, "%d\tlasso-sparse\tNA\t%.4f\t%.4f\tNA\tNA\tNA\tNA\tNA\tNA\n", best+1, trylams[best], tryscales[best]);}
if(trytypes[best]==2){fprintf(output3, "%d\tlasso\t%.4f\tNA\tNA\tNA\tNA\tNA\tNA\tNA\tNA\n", best+1, tryhers[best]);}
if(trytypes[best]==3){fprintf(output3, "%d\tridge\t%.4f\tNA\tNA\tNA\tNA\tNA\tNA\tNA\tNA\n", best+1, tryhers[best]);}
if(trytypes[best]==4){fprintf(output3, "%d\tbolt\t%.4f\tNA\tNA\t%.4f\t%.4f\tNA\tNA\tNA\tNA\n", best+1, tryhers[best], tryps[best], tryf2s[best]);}
if(trytypes[best]==5){fprintf(output3, "%d\tbayesr\t%.4f\tNA\tNA\tNA\tNA\t%.4f\t%.4f\t%.4f\t%.4f\n", best+1, tryhers[best], tryps[best], tryp2s[best], tryp3s[best], tryp4s[best]);}
if(trytypes[best]==6){fprintf(output3, "%d\tbayesr-shrink\t%.4f\tNA\tNA\tNA\tNA\t%.4f\t%.4f\t%.4f\t%.4f\n", best+1, tryhers[best], tryps[best], tryp2s[best], tryp3s[best], tryp4s[best]);}
if(trytypes[best]==7){fprintf(output3, "%d\telastic\t%.4f\tNA\tNA\t%.4f\t%.4f\tNA\tNA\tNA\tNA\n", best+1, tryhers[best], 1-tryp3s[best], tryf2s[best]);}
fclose(output3);

printf("The estimated correlations of models are saved in %s, while the parameters corresponding to the best model are saved in %s\n\n", filename2, filename3);
}	//end of not trivial
}	//end of using training and test summary statistics

////////

//solve for main statistics - var(Y)=1, so YTY=neff

//set start and end
if(skipcv==0)	//test only best model
{start=best;end=best+1;}
else	//test all models
{start=0;end=num_try;}

//screen and file print
if(skipcv==0){printf("Estimating effect sizes using the best parameters and summary statistics in %s\n\n", sumsfile);}
else{printf("Estimating effect sizes for %d models using summary statistics in %s (if using multiple cores, models will finish in a random order)\n\n", end-start, sumsfile);}

if((output=fopen(filename,"a"))==NULL)
{printf("Error re-opening %s\n\n",filename);exit(1);}
fprintf(output,"Constructing %d models using summary statistics in %s\n", end-start, sumsfile);
fprintf(output, "Model\tType\tHeritability\tlambda\tscale\tp\tf2\tp1\tp2\tp3\tp4\tNum_Predictors_Failed\n");
fclose(output);

//get XTX and XTY for each predictor
for(j=0;j<data_length;j++){datasqs[j]=neff;YTdata[j]=rhos[j]*neff;}

//set starting effect based on type of model, and set probablities to zero
#pragma omp parallel for private(p,j,value,value2) schedule(dynamic, 1)
for(p=start;p<end;p++)
{
for(j=0;j<data_length;j++)
{
if(exps[j]>0)
{
//value and value2 are how much to scale gaussian and laplace parameters
value=exps[j]*tryhers[p];
value2=pow(exps[j]*tryhers[p],-.5);

if(trytypes[p]==1)	//lasso-sparse - set to zero
{effs[(size_t)p*data_length+j]=0;}
if(trytypes[p]==2)	//lasso - posterior mean, weighted by tagging
{effs[(size_t)p*data_length+j]=get_postmean(YTdata[j], lambdas[p]*value2, -9999, -9999, -9999, datasqs[j], 1.0, -9999, -9999, -9999, -9999, NULL, 2, NULL)/rjksums[j];}
if(trytypes[p]==3)	//ridge - posterior mean, weighted by tagging
{effs[(size_t)p*data_length+j]=get_postmean(YTdata[j], lambdas[p]*value, -9999, -9999, -9999, datasqs[j], 1.0, -9999, -9999, -9999, -9999, NULL, 3, NULL)/rjksums[j];}
if(trytypes[p]==4)	//bolt - posterior mean, weighted by tagging
{effs[(size_t)p*data_length+j]=get_postmean(YTdata[j], lambdas[p]*value, lambdas2[p]*value, -9999, -9999, datasqs[j], 1.0, tryps[p], tryp2s[p], -9999, -9999, NULL, 4, NULL)/rjksums[j];}
if(trytypes[p]==5||trytypes[p]==6)	//bayesr or bayesr-shrink - posterior mean, weighted by tagging
{effs[(size_t)p*data_length+j]=get_postmean(YTdata[j], lambdas[p]*value, lambdas2[p]*value, lambdas3[p]*value, lambdas4[p]*value, datasqs[j], 1.0, tryps[p], tryp2s[p], tryp3s[p], tryp4s[p], NULL, trytypes[p], NULL)/rjksums[j];}
if(trytypes[p]==7)	//elastic - posterior mean, weighted by tagging
{effs[(size_t)p*data_length+j]=get_postmean(YTdata[j], lambdas[p]*value2, lambdas2[p]*value2, lambdas3[p]*value, -9999, datasqs[j], 1.0, tryps[p], tryp2s[p], tryp3s[p], -9999, NULL, 7, NULL)/rjksums[j];}
}
else	//set to zero
{effs[(size_t)p*data_length+j]=0;}

probs[(size_t)p*data_length+j]=0;
}
}

//now ready to train models
#pragma omp parallel for private(p,j,j2,count,bitstart,bitstart2,bitend,bitlength,sum,value,value2,sumsq,sumsq2,window_kb2) schedule(dynamic, 1)
for(p=start;p<end;p++)
{
//set convs to zero
for(j=0;j<data_length;j++){convs[(size_t)p*data_length+j]=0;}

window_kb2=window_kb/segments;
bitstart=0;
while(bitstart<data_length)
{
for(bitend=bitstart+1;bitend<data_length;bitend++)
{
if(cmbp[bitend]-cmbp[bitstart]>1000*window_kb2||chr[bitend]!=chr[bitstart]){break;}
}
bitlength=bitend-bitstart;

//calculate ess for bit
sumsq=0;
for(j=bitstart;j<bitend;j++)
{
sumsq+=2*YTdata[j]*effs[(size_t)p*data_length+j]-datasqs[j]*pow(effs[(size_t)p*data_length+j],2);
for(j2=0;j2<actnums[j];j2++)
{
if(bigs[j][j2]>=bitstart&&bigs[j][j2]<bitend)
{sumsq-=rjks[j][j2]*neff*effs[(size_t)p*data_length+j]*effs[(size_t)p*data_length+bigs[j][j2]];}
}
}

//save effect sizes for bit, in case fail to converge
for(j=0;j<bitlength;j++)
{effs2[j+p*bitmax]=effs[(size_t)p*data_length+bitstart+j];probs2[j+p*bitmax]=probs[(size_t)p*data_length+bitstart+j];}

count=0;
while(1)
{
count++;

for(j=bitstart;j<bitend;j++)
{
if(exps[j]>0)
{
//get XjT residuals
sum=YTdata[j];
for(j2=0;j2<actnums[j];j2++){sum-=tryscales[p]*rjks[j][j2]*neff*effs[(size_t)p*data_length+bigs[j][j2]];}

//value and value2 are how much to scale gaussian and laplace parameters
value=exps[j]*tryhers[p];
value2=pow(exps[j]*tryhers[p],-.5);

//update effect size
if(trytypes[p]==1)	//lasso-sparse
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value2*neff2, -9999, -9999, -9999, datasqs[j], 1.0, -9999, -9999, -9999, -9999, NULL, 1, NULL);}
if(trytypes[p]==2)	//lasso
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value2, -9999, -9999, -9999, datasqs[j], 1.0, -9999, -9999, -9999, -9999, NULL, 2, probs+(size_t)p*data_length+j);}
if(trytypes[p]==3)	//ridge
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value, -9999, -9999, -9999, datasqs[j], 1.0, -9999, -9999, -9999, -9999, NULL, 3, probs+(size_t)p*data_length+j);}
if(trytypes[p]==4)	//bolt
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value, lambdas2[p]*value, -9999, -9999, datasqs[j], 1.0, tryps[p], tryp2s[p], -9999, -9999, NULL, 4, probs+(size_t)p*data_length+j);}
if(trytypes[p]==5||trytypes[p]==6)	//bayesr or bayesr-shrink
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value, lambdas2[p]*value, lambdas3[p]*value, lambdas4[p]*value, datasqs[j], 1.0, tryps[p], tryp2s[p], tryp3s[p], tryp4s[p], NULL, trytypes[p], probs+(size_t)p*data_length+j);}
if(trytypes[p]==7)	//elastic
{effs[(size_t)p*data_length+j]=get_postmean(sum, lambdas[p]*value2, lambdas2[p]*value2, lambdas3[p]*value, -9999, datasqs[j], 1.0, tryps[p], tryp2s[p], tryp3s[p], -9999, NULL, 7, probs+(size_t)p*data_length+j);}
}
}	//end of j loop

//save old then calculate new ess for bit
sumsq2=sumsq;
sumsq=0;
for(j=bitstart;j<bitend;j++)
{
sumsq+=2*YTdata[j]*effs[(size_t)p*data_length+j]-datasqs[j]*pow(effs[(size_t)p*data_length+j],2);
for(j2=0;j2<actnums[j];j2++)
{
if(bigs[j][j2]>=bitstart&&bigs[j][j2]<bitend)
{sumsq-=rjks[j][j2]*neff*effs[(size_t)p*data_length+j]*effs[(size_t)p*data_length+bigs[j][j2]];}
}
}

if(fabs(sumsq-sumsq2)/neff<tol)	//converged
{
for(j=bitstart;j<bitend;j++){convs[(size_t)p*data_length+j]=1;}

if(window_kb2==window_kb)	//did a full window, so move start forwards window_kb/segments
{
for(bitstart2=bitstart+1;bitstart2<data_length;bitstart2++)
{
if(cmbp[bitstart2]-cmbp[bitstart]>1000*window_kb/segments||chr[bitstart2]!=chr[bitstart]){break;}
}
if(bitstart2==bitend)	//must have been at end of chromosome
{window_kb2=window_kb/segments;}
bitstart=bitstart2;
}
else	//did a small window, so start stays same, but increase window size
{window_kb2*=2;}

break;
}

if(sumsq>=neff||count==maxiter)	//failed (almost certainly due to end of bit) - undo iterations, skip rest of bit, and reduce window size 
{
//note that if here, bitstart will not have been updated
for(j=0;j<bitlength;j++)
{effs[(size_t)p*data_length+bitstart+j]=effs2[j+p*bitmax];probs[(size_t)p*data_length+bitstart+j]=probs2[j+p*bitmax];}
bitstart=bitend;
window_kb2=window_kb/segments;
break;
}
}	//end of inside while loop

}	//end of outside while loop

//count how many failed to converged
count=0;for(j=0;j<data_length;j++){count+=(exps[j]>0&&convs[(size_t)p*data_length+j]==0);}

//print update
#pragma omp critical
{
printf("Constructed Model %d: ", p-start+1);
if(trytypes[p]==1){printf("lasso-sparse, lambda %.4f, scale %.4f", trylams[p], tryscales[p]);}
if(trytypes[p]==2){printf("lasso, heritability %.4f", tryhers[p]);}
if(trytypes[p]==3){printf("ridge, heritability %.4f", tryhers[p]);}
if(trytypes[p]==4){printf("bolt, heritability %.4f, p %.4f, f2 %.4f", tryhers[p], tryps[p], tryf2s[p]);}
if(trytypes[p]==5){printf("bayesr, heritability %.4f, p1 %.4f, p2 %.4f, p3 %.4f, p4 %.4f", tryhers[p], tryps[p], tryp2s[p], tryp3s[p], tryp4s[p]);}
if(trytypes[p]==6){printf("bayesr-shrink, heritability %.4f, p1 %.4f, p2 %.4f, p3 %.4f, p4 %.4f", tryhers[p], tryps[p], tryp2s[p], tryp3s[p], tryp4s[p]);}
if(trytypes[p]==7){printf("elastic, heritability %.4f, p %.4f, f2 %.4f", tryhers[p], 1-tryp3s[p], tryf2s[p]);}
if(count==0){printf(" - effect sizes converged for all predictors\n");}
else{printf(" - effect sizes failed to converge for %d predictors\n", count);}

if((output=fopen(filename,"a"))==NULL)
{printf("Error re-opening %s\n\n",filename);exit(1);}
fprintf(output, "%d\t", p-start+1);
if(trytypes[p]==1){fprintf(output, "lasso-sparse\tNA\t%.4f\t%.4f\tNA\tNA\tNA\tNA\tNA\tNA\t%d\n", trylams[p], tryscales[p], count);}
if(trytypes[p]==2){fprintf(output, "lasso\t%.4f\tNA\tNA\tNA\tNA\tNA\tNA\tNA\tNA\t%d\n", tryhers[p], count);}
if(trytypes[p]==3){fprintf(output, "ridge\t%.4f\tNA\tNA\tNA\tNA\tNA\tNA\tNA\tNA\t%d\n", tryhers[p], count);}
if(trytypes[p]==4){fprintf(output, "bolt\t%.4f\tNA\tNA\t%.4f\t%.4f\tNA\tNA\tNA\tNA\t%d\n", tryhers[p], tryps[p], tryf2s[p], count);}
if(trytypes[p]==5){fprintf(output, "bayesr\t%.4f\tNA\tNA\tNA\tNA\t%.4f\t%.4f\t%.4f\t%.4f\t%d\n", tryhers[p], tryps[p], tryp2s[p], tryp3s[p], tryp4s[p], count);}
if(trytypes[p]==6){fprintf(output, "bayesr-shrink\t%.4f\tNA\tNA\tNA\t%.4f\t%.4f\t%.4f\t%.4f\t%d\n", tryhers[p], tryps[p], tryp2s[p], tryp3s[p], tryp4s[p], count);}
if(trytypes[p]==7){fprintf(output, "elastic\t%.4f\tNA\tNA\t%.4f\t%.4f\tNA\tNA\tNA\tNA\t%d\n", tryhers[p], 1-tryp3s[p], tryf2s[p], count);}
fclose(output);
}
}	//end of p loop
printf("\n");

//save models
sprintf(filename2,"%s.effects",outfile);
if((output2=fopen(filename2,"w"))==NULL)
{printf("Error writing to %s; check you have permission to write and that there does not exist a folder with this name\n\n",filename2);exit(1);}

fprintf(output2,"Predictor A1 A2 Centre");
for(p=start;p<end;p++){fprintf(output2," Model%d", p+1);}
fprintf(output2,"\n");
for(j=0;j<data_length;j++)
{
if(exps[j]>0)
{
fprintf(output2, "%s %c %c %.6f", preds[j], al1[j], al2[j], centres[j]);
for(p=start;p<end;p++){fprintf(output2," %.4e", effs[(size_t)p*data_length+j]*mults[j]);}
fprintf(output2,"\n");
}
}
fclose(output2);

sprintf(filename3,"%s.probs",outfile);
if((output3=fopen(filename3,"w"))==NULL)
{printf("Error writing to %s; check you have permission to write and that there does not exist a folder with this name\n\n",filename3);exit(1);}
fprintf(output3,"Predictor");
for(p=start;p<end;p++){fprintf(output3," Model%d", p+1);}
fprintf(output3,"\n");

for(j=0;j<data_length;j++)
{
fprintf(output3, "%s ", preds[j]);
for(p=start;p<end;p++){fprintf(output3," %.4e", probs[(size_t)p*data_length+j]);}
fprintf(output3,"\n");
}
fclose(output3);

if(end-start==1){printf("Model saved in %s, with posterior probabilities in %s\n\n", filename2, filename3);}
else{printf("Models saved in %s, with posterior probabilities in %s\n\n", filename2, filename3);}

free(trytypes);free(tryhers);free(trylams);free(tryscales);free(tryps);free(tryp2s);free(tryp3s);free(tryp4s);free(tryf2s);
if(skipcv==0){free(nss2);free(rhos2);free(rhos3);}
if(skipcv==0){free(highlds);}
free(maxnums);free(scumsums);
for(j=0;j<data_length;j++){free(bigs[j]);free(rjks[j]);}free(bigs);free(rjks);
free(usedpreds);free(actnums);free(rjksums);
free(datasqs);free(YTdata);
free(exps);
free(lambdas);free(lambdas2);free(lambdas3);free(lambdas4);
free(effs);free(effs2);free(probs);free(probs2);
free(convs);
if(skipcv==0){free(predvars);free(predcors);}

///////////////////////////

